name: Check URL Freshness

on:
  schedule:
    - cron: '0 6 * * *' # Run daily at 6 AM UTC
  workflow_dispatch: # Allow manual triggering

jobs:
  check-url-freshness:
    name: Check URL Freshness
    runs-on: ubuntu-latest
    permissions:
      contents: read
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Download previous timestamps
        uses: dawidd6/action-download-artifact@v6
        with:
          name: url-timestamps
          path: .url-timestamps
          if_no_artifact_found: warn
          workflow_conclusion: success
          search_artifacts: true
        continue-on-error: true

      - name: Check URL freshness
        id: check
        shell: bash
        run: |
          set -euo pipefail

          TIMESTAMPS_FILE=".url-timestamps/timestamps.json"
          NEW_TIMESTAMPS_FILE=".url-timestamps-new/timestamps.json"
          REPORT_FILE=".url-timestamps-new/report.md"
          USER_AGENT="Mozilla/5.0 (compatible; ScoopBucketChecker/1.0; +https://github.com/${{ github.repository }})"

          mkdir -p .url-timestamps-new

          # Initialize previous timestamps
          if [ -f "$TIMESTAMPS_FILE" ]; then
            PREV_TIMESTAMPS=$(cat "$TIMESTAMPS_FILE")
          else
            PREV_TIMESTAMPS="{}"
          fi

          # Initialize new timestamps and report
          echo "{}" > "$NEW_TIMESTAMPS_FILE"
          {
            echo "# URL Freshness Report"
            echo ""
            echo "Generated: $(date -u '+%Y-%m-%d %H:%M:%S UTC')"
            echo ""
          } > "$REPORT_FILE"

          # Use arrays for safe string accumulation
          declare -a UPDATED_ITEMS=()
          declare -a NEW_ITEMS=()
          declare -a FAILED_ITEMS=()

          # Process each manifest file using nullglob to handle no matches gracefully
          shopt -s nullglob
          for manifest in bucket/*.json; do
            app_name=$(basename "$manifest" .json)

            # Extract URLs from the manifest using null delimiter for safe reading
            while IFS= read -r -d '' url; do
              if [ -z "$url" ] || [ "$url" = "null" ]; then
                continue
              fi

              # Remove fragment from URL (e.g., #/dl.exe) using bash parameter expansion
              clean_url="${url%%#*}"

              echo "Checking: $app_name - $clean_url"

              # Get Last-Modified header using HEAD request with user agent and limited redirects
              # Capture curl output and exit code, handling failures gracefully with set -e
              curl_exit_code=0
              response=$(curl -sI -L --max-redirs 5 --max-time 30 -A "$USER_AGENT" "$clean_url" 2>/dev/null) || curl_exit_code=$?
              last_modified=$(echo "$response" | grep -i "^last-modified:" | tail -1 | sed 's/^[Ll]ast-[Mm]odified: *//' | tr -d '\r' || true)

              if [ -z "$last_modified" ]; then
                if [ "$curl_exit_code" -ne 0 ]; then
                  echo "  Warning: Connection failed (curl exit code: $curl_exit_code)"
                  FAILED_ITEMS+=("- **${app_name}**: \`${clean_url}\` (Connection failed, curl exit code: $curl_exit_code)")
                else
                  echo "  Warning: No Last-Modified header found"
                  FAILED_ITEMS+=("- **${app_name}**: \`${clean_url}\` (No Last-Modified header)")
                fi
                # Store empty value but continue
                NEW_TIMESTAMPS=$(jq --arg key "$clean_url" --arg val "" '. + {($key): $val}' "$NEW_TIMESTAMPS_FILE")
                echo "$NEW_TIMESTAMPS" > "$NEW_TIMESTAMPS_FILE"
                continue
              fi

              echo "  Last-Modified: $last_modified"

              # Store new timestamp
              NEW_TIMESTAMPS=$(jq --arg key "$clean_url" --arg val "$last_modified" '. + {($key): $val}' "$NEW_TIMESTAMPS_FILE")
              echo "$NEW_TIMESTAMPS" > "$NEW_TIMESTAMPS_FILE"

              # Get previous timestamp
              prev_timestamp=$(echo "$PREV_TIMESTAMPS" | jq -r --arg key "$clean_url" '.[$key] // ""')

              if [ -z "$prev_timestamp" ]; then
                echo "  Status: New URL (not previously tracked)"
                NEW_ITEMS+=("- **${app_name}**: \`${clean_url}\`" "  - Last-Modified: ${last_modified}")
              elif [ "$prev_timestamp" != "$last_modified" ]; then
                echo "  Status: UPDATED! (was: $prev_timestamp)"
                UPDATED_ITEMS+=("- **${app_name}**: \`${clean_url}\`" "  - Previous: ${prev_timestamp}" "  - Current: ${last_modified}")
              else
                echo "  Status: Unchanged"
              fi
            done < <(jq -j '
              [
                .url,
                .architecture?.["64bit"]?.url,
                .architecture?.["32bit"]?.url,
                .architecture?.arm64?.url
              ] | map(select(. != null)) | .[] | (. + "\u0000")
            ' "$manifest" 2>/dev/null || true)
          done
          shopt -u nullglob

          # Generate report
          if [ ${#UPDATED_ITEMS[@]} -gt 0 ]; then
            {
              echo "## âš ï¸ Updated URLs Detected"
              echo ""
              echo "The following URLs have been modified since the last check:"
              echo ""
              printf '%s\n' "${UPDATED_ITEMS[@]}"
              echo ""
            } >> "$REPORT_FILE"
            echo "has_updates=true" >> "$GITHUB_OUTPUT"
          else
            {
              echo "## âœ… No Updated URLs"
              echo ""
              echo "All tracked URLs have the same Last-Modified dates as the previous check."
              echo ""
            } >> "$REPORT_FILE"
            echo "has_updates=false" >> "$GITHUB_OUTPUT"
          fi

          if [ ${#NEW_ITEMS[@]} -gt 0 ]; then
            {
              echo "## ðŸ†• New URLs"
              echo ""
              echo "The following URLs are newly tracked:"
              echo ""
              printf '%s\n' "${NEW_ITEMS[@]}"
              echo ""
            } >> "$REPORT_FILE"
          fi

          if [ ${#FAILED_ITEMS[@]} -gt 0 ]; then
            {
              echo "## âŒ URLs With Issues"
              echo ""
              echo "The following URLs had issues during checking:"
              echo ""
              printf '%s\n' "${FAILED_ITEMS[@]}"
              echo ""
            } >> "$REPORT_FILE"
          fi

          # Output report to job summary
          cat "$REPORT_FILE" >> "$GITHUB_STEP_SUMMARY"

      - name: Upload new timestamps
        uses: actions/upload-artifact@v4
        with:
          name: url-timestamps
          path: .url-timestamps-new/timestamps.json
          retention-days: 90
          overwrite: true
